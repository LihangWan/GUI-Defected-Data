"""
æ•°æ®è´¨é‡æ·±åº¦åˆ†æå·¥å…·
"""
import json
from pathlib import Path
from collections import defaultdict, Counter

meta_dir = Path("dataset_injected/raw_metadata")
all_meta = [json.loads(f.read_text(encoding='utf-8')) for f in meta_dir.glob("int_*.json")]

print(f"\n{'='*70}")
print(f"ğŸ“Š æ•°æ®è´¨é‡æ·±åº¦åˆ†ææŠ¥å‘Š")
print(f"{'='*70}")
print(f"æ€»æ ·æœ¬æ•°: {len(all_meta)}")

# 1. ç»¼åˆéªŒè¯ç»Ÿè®¡
verified = sum(m.get("injection_verified", False) for m in all_meta)
visual_verified = sum(m.get("visual_verified", False) for m in all_meta)
has_logs = sum(m.get("has_network_logs", False) for m in all_meta)

print(f"\nã€ç»¼åˆéªŒè¯ç‡ã€‘")
print(f"  injection_verified: {verified}/{len(all_meta)} ({verified/len(all_meta)*100:.1f}%)")
print(f"  visual_verified:    {visual_verified}/{len(all_meta)} ({visual_verified/len(all_meta)*100:.1f}%)")
print(f"  has_network_logs:   {has_logs}/{len(all_meta)} ({has_logs/len(all_meta)*100:.1f}%)")

quality_score = (verified/len(all_meta)*0.6 + visual_verified/len(all_meta)*0.4)*100
print(f"\n  ğŸ¯ è´¨é‡å¾—åˆ†: {quality_score:.1f}/100")
if quality_score >= 80:
    print(f"     è¯„çº§: â­â­â­ å“è¶Š")
elif quality_score >= 60:
    print(f"     è¯„çº§: â­â­ è‰¯å¥½")
elif quality_score >= 40:
    print(f"     è¯„çº§: â­ åŠæ ¼")
else:
    print(f"     è¯„çº§: âš ï¸ éœ€æ”¹è¿›")

# 2. æŒ‰Bugç±»å‹ç»Ÿè®¡
bug_stats = defaultdict(lambda: {"total": 0, "verified": 0, "visual_verified": 0, "has_logs": 0})

for m in all_meta:
    bt = m["bug_type"]
    bug_stats[bt]["total"] += 1
    if m.get("injection_verified"):
        bug_stats[bt]["verified"] += 1
    if m.get("visual_verified"):
        bug_stats[bt]["visual_verified"] += 1
    if m.get("has_network_logs"):
        bug_stats[bt]["has_logs"] += 1

print(f"\n{'='*70}")
print(f"ã€æŒ‰Bugç±»å‹åˆ†æã€‘")
print(f"{'='*70}")
for bug, stats in sorted(bug_stats.items(), key=lambda x: x[1]["verified"]/x[1]["total"], reverse=True):
    v_rate = stats["verified"] / stats["total"] * 100
    vis_rate = stats["visual_verified"] / stats["total"] * 100
    log_rate = stats["has_logs"] / stats["total"] * 100
    
    rating = "â­â­â­" if v_rate >= 80 else "â­â­" if v_rate >= 60 else "â­" if v_rate >= 40 else "âš ï¸"
    
    print(f"\n{bug} {rating}")
    print(f"  æ€»æ•°: {stats['total']}")
    print(f"  éªŒè¯ç‡:      {v_rate:.1f}%  {'âœ“' if v_rate >= 70 else 'âœ—'}")
    print(f"  è§†è§‰éªŒè¯ç‡:  {vis_rate:.1f}%  {'âœ“' if vis_rate >= 60 else 'âœ—'}")
    print(f"  ç½‘ç»œæ—¥å¿—ç‡:  {log_rate:.1f}%  {'âœ“' if log_rate >= 80 else 'âœ—'}")

# 3. é«˜è´¨é‡æ ·æœ¬åˆ†æ
high_quality = [m for m in all_meta if m.get("injection_verified") and m.get("visual_verified")]
print(f"\n{'='*70}")
print(f"ã€é«˜è´¨é‡æ ·æœ¬ç‰¹å¾ã€‘(verified=True + visual_verified=True)")
print(f"{'='*70}")
print(f"æ•°é‡: {len(high_quality)}/{len(all_meta)} ({len(high_quality)/len(all_meta)*100:.1f}%)")

if high_quality:
    print(f"\næœ€å¸¸è§å…ƒç´ ç±»å‹:")
    elem_types = [m["element_semantic"]["tag"] for m in high_quality]
    for tag, count in Counter(elem_types).most_common(5):
        print(f"  â€¢ {tag}: {count}")
    
    print(f"\næœ€å¸¸è§Bugç±»å‹:")
    bug_types = [m["bug_type"] for m in high_quality]
    for bug, count in Counter(bug_types).most_common():
        print(f"  â€¢ {bug}: {count}")
    
    print(f"\nå¹³å‡è§†è§‰ä¿¡å·:")
    avg_similarity = sum(m.get("visual_signals", {}).get("similarity", 0) for m in high_quality) / len(high_quality)
    has_spinner = sum(m.get("visual_signals", {}).get("has_spinner", False) for m in high_quality)
    has_error = sum(m.get("visual_signals", {}).get("has_error_ele", False) for m in high_quality)
    print(f"  ç›¸ä¼¼åº¦: {avg_similarity:.3f}")
    print(f"  æœ‰spinner: {has_spinner}/{len(high_quality)}")
    print(f"  æœ‰errorå…ƒç´ : {has_error}/{len(high_quality)}")

# 4. ä½è´¨é‡æ ·æœ¬åˆ†æ
low_quality = [m for m in all_meta if not m.get("injection_verified")]
print(f"\n{'='*70}")
print(f"ã€ä½è´¨é‡æ ·æœ¬è¯Šæ–­ã€‘(verified=False)")
print(f"{'='*70}")
print(f"æ•°é‡: {len(low_quality)}/{len(all_meta)} ({len(low_quality)/len(all_meta)*100:.1f}%)")

if low_quality:
    print(f"\nå¸¸è§å¤±è´¥å…ƒç´ ç±»å‹:")
    elem_types = [m["element_semantic"]["tag"] for m in low_quality]
    for tag, count in Counter(elem_types).most_common(5):
        print(f"  â€¢ {tag}: {count}")
    
    print(f"\nå¸¸è§å¤±è´¥Bugç±»å‹:")
    bug_types = [m["bug_type"] for m in low_quality]
    for bug, count in Counter(bug_types).most_common():
        print(f"  â€¢ {bug}: {count}")
    
    # æ— ç½‘ç»œæ—¥å¿—çš„æ¯”ä¾‹
    no_logs = sum(1 for m in low_quality if not m.get("has_network_logs"))
    print(f"\næ— ç½‘ç»œæ—¥å¿—: {no_logs}/{len(low_quality)} ({no_logs/len(low_quality)*100:.1f}%)")
    
    print(f"\nå…¸å‹å¤±è´¥æ¡ˆä¾‹ï¼ˆå‰3ä¸ªï¼‰:")
    for i, m in enumerate(low_quality[:3], 1):
        print(f"\n  {i}. {m['id']}")
        print(f"     Bug: {m['bug_type']}")
        print(f"     å…ƒç´ : {m['element_semantic']['tag']} - {m['element_semantic']['readable_name'][:40]}")
        print(f"     ç½‘ç»œæ—¥å¿—: {len(m.get('interceptor_logs', []))}")
        signals = m.get('visual_signals', {})
        print(f"     è§†è§‰ä¿¡å·: similarity={signals.get('similarity', 0):.3f}, "
              f"spinner={signals.get('has_spinner', False)}, "
              f"error={signals.get('has_error_ele', False)}")

# 5. å»ºè®®
print(f"\n{'='*70}")
print(f"ã€ä¼˜åŒ–å»ºè®®ã€‘")
print(f"{'='*70}")

issues = []
if verified/len(all_meta) < 0.7:
    issues.append("éªŒè¯ç‡åä½")
if visual_verified/len(all_meta) < 0.6:
    issues.append("è§†è§‰éªŒè¯ç‡åä½")
if has_logs/len(all_meta) < 0.8:
    issues.append("ç½‘ç»œæ‹¦æˆªæˆåŠŸç‡ä½")

if not issues:
    print("âœ… æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œæ— æ˜æ˜¾é—®é¢˜ï¼")
else:
    print(f"âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜:\n")
    
    if "éªŒè¯ç‡åä½" in issues:
        print("1. ã€éªŒè¯ç‡åä½ã€‘")
        print("   â†’ ä¼˜åŒ–å€™é€‰å…ƒç´ é€‰æ‹©ï¼Œè¿‡æ»¤æ— æ•ˆå…ƒç´ ï¼ˆå‚è€ƒ quality_check_guide.md ç­–ç•¥2ï¼‰")
        print("   â†’ æå‰æ³¨å…¥JSæ‹¦æˆªå™¨ï¼ˆç­–ç•¥1ï¼‰\n")
    
    if "è§†è§‰éªŒè¯ç‡åä½" in issues:
        print("2. ã€è§†è§‰éªŒè¯ç‡åä½ã€‘")
        print("   â†’ æ”¾å®½å¯å‘å¼è§„åˆ™åˆ¤å®šæ¡ä»¶ï¼ˆç­–ç•¥3ï¼‰")
        print("   â†’ å¢åŠ å¼‚æ­¥UIæ•æ‰ç­‰å¾…æ—¶é—´ï¼ˆç­–ç•¥4ï¼‰\n")
    
    if "ç½‘ç»œæ‹¦æˆªæˆåŠŸç‡ä½" in issues:
        print("3. ã€ç½‘ç»œæ‹¦æˆªæˆåŠŸç‡ä½ã€‘")
        # åˆ†æå¤±è´¥åŸå› 
        no_log_samples = [m for m in all_meta if not m.get("has_network_logs")]
        if no_log_samples:
            failed_bugs = Counter([m["bug_type"] for m in no_log_samples])
            print(f"   æ— æ—¥å¿—Bugç±»å‹åˆ†å¸ƒ: {dict(failed_bugs)}")
            print("   â†’ æŸäº›Bugç±»å‹çš„å…ƒç´ å¯èƒ½ä¸è§¦å‘ç½‘ç»œè¯·æ±‚")
            print("   â†’ è€ƒè™‘ä¸ºè¿™äº›Bugç±»å‹å•ç‹¬ä¼˜åŒ–å…ƒç´ é€‰æ‹©é€»è¾‘\n")

print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥è¡ŒåŠ¨:")
print(f"1. æŸ¥çœ‹ quality_check_guide.md è·å–è¯¦ç»†ä¼˜åŒ–æ–¹æ¡ˆ")
print(f"2. è¿è¡Œ visual_review.py ç”Ÿæˆå¯è§†åŒ–å®¡æŸ¥å›¾åƒ")
print(f"3. å®æ–½ä¸€é¡¹ä¼˜åŒ–åï¼Œé‡æ–°ç”Ÿæˆ10-20ä¸ªæ ·æœ¬å¯¹æ¯”æ•ˆæœ")
print(f"{'='*70}\n")
